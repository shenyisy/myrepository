**macrotrend_crawler.py**
使用说明
    1. https://www.macrotrends.net/stocks/charts/KO/cocacola/income-statement网站的页面数据为报表类型，具备拖动条属于动态加载类型
        因此当前脚本的WebDriver基于分分辨率为 2560*1440，如果有显示器分辨率有变化需要进行调整


执行说明

    1.  配置 WebDriver：代码首先配置了 Chrome 浏览器的 WebDriver，包括设置代理服务器、窗口大小等参数。
    2.  访问目标网页：使用 WebDriver 打开目标网页，该网页是可口可乐公司（KO）的财务报表页面。
    3.  广告屏蔽：通过执行 JavaScript 代码隐藏页面上的广告元素，以减少干扰。
    4.  数据提取功能：
    •   extract_data() 函数通过两个不同的 XPath 范围提取财务数据。函数首先滚动页面到特定位置，然后依次获取报告日期和对应的财务字段数据。
    •   提取到的数据经过格式化处理，例如去除 $ 符号、逗号等，并将数据转换为浮点数。
    •   数据被存储在一个字典中，其中报告日期作为键，相关的财务数据作为值。
    5.  滚动条操作：为了确保所有财务数据可见，当某些条件满足时，代码会自动移动水平滚动条以加载更多数据。
    6.  数据插入：提取的财务数据被收集到一个列表中，然后逐条插入到 MySQL 数据库中。
    7.  错误处理：代码使用 try-except 结构来捕获和处理可能的异常，例如数据提取失败、数据库连接错误等。
    8.  资源清理：在执行结束或出现错误时，代码确保关闭数据库连接和浏览器，以释放资源。



**wsj_crawler.py**
使用说明
    1. https://www.wsj.com/pro/venture-capital/topics/fin-tech网站的页面数据为新闻资讯类
    2. 网站有很强的反扒机制（设备验证、活体验证、封锁IP）
    3、当前解决方案为使用cookies绕过验证，首次执行必须手动获取后放到代码目录 news_crawler/cookies/wsj_cookies
    4、cookies获取可以通过Chrome浏览器插件“Cookies Tool”获取

执行过程

    1.  配置浏览器和代理：代码首先配置了 Chrome 浏览器的 WebDriver，并设置了代理服务器，以应对可能的地区限制或访问速度问题。
    2.  解析 Cookie 文件：parse_cookies_from_file() 函数从指定的文件中读取 Cookie，将其解析为浏览器可用的格式。这些 Cookie 用于网页访问时的身份验证和绕过部分访问限制。
    3.  初始化 WebDriver 并连接数据库：extract_news_from_wsj() 函数启动浏览器，设置等待机制，并尝试连接数据库。数据库连接成功后，开始执行数据提取操作。
    4.  访问目标网页：脚本通过 WebDriver 访问《华尔街日报》的特定页面，并加载 Cookie 后刷新网页，以确保能够成功访问受保护的内容。
    5.  动态加载更多内容：通过模拟点击 “LOAD MORE” 按钮，脚本最多点击 10 次，逐步加载更多的新闻文章，模拟用户的操作以获取更多数据。
    6.  提取文章日期和链接：脚本从页面中提取所有的日期和链接元素，并将其存储在列表中。这些信息用于后续的数据提取。
    7.  访问每篇文章并提取内容：
    •   打开每个提取到的文章链接，并在页面中添加 Cookie 后刷新页面。
    •   通过指定的 CSS 选择器，提取每篇文章的标题、第一段和第二段的内容。
    •   将这些内容格式化为指定的日期格式，并将提取到的数据插入到数据库中。
    8.  错误处理和资源清理：脚本在各个步骤中都加入了异常处理机制，以捕捉和记录可能发生的错误，确保即使发生问题也不会导致程序崩溃。任务完成后，会关闭浏览器和数据库连接，释放资源。

